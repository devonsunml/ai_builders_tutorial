{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Responses API: Complete Tutorial\n",
    "\n",
    "## Overview\n",
    "\n",
    "The OpenAI Responses API is a superset of Chat Completions, meaning everything you can do with Chat Completions can be done with the Responses API, plus additional features. This unified interface simplifies building AI applications with built-in tools, conversation management, and enhanced capabilities.\n",
    "\n",
    "### Key Features\n",
    "- **Simplified Interface**: Single API for complex interactions\n",
    "- **Built-in Tools**: Web search, file search, computer use\n",
    "- **Stateful Conversations**: Automatic conversation management\n",
    "- **Structured Outputs**: Type-safe responses with Pydantic\n",
    "- **Enhanced Function Calling**: Custom tool integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple text generation\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Write a haiku about artificial intelligence.\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions vs Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using instructions for system-level guidance\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"You are a helpful coding assistant. Always provide working code examples.\",\n",
    "    input=\"How do I read a CSV file in Python?\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conversation State Management\n",
    "\n",
    "### Manual State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build conversation manually\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the population?\"}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=conversation\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let OpenAI handle conversation state\n",
    "response1 = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"Tell me about Python programming.\"\n",
    ")\n",
    "\n",
    "# Continue conversation using previous response ID\n",
    "response2 = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    previous_response_id=response1.id,\n",
    "    input=\"What are its main advantages?\"\n",
    ")\n",
    "\n",
    "print(\"First response:\", response1.output_text)\n",
    "print(\"\\nSecond response:\", response2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom functions\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current weather for a location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\"type\": \"string\", \"description\": \"City name\"},\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"What's the weather like in Tokyo?\",\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# Check if function was called\n",
    "for output in response.output:\n",
    "    if hasattr(output, 'function_call'):\n",
    "        print(f\"Function called: {output.function_call.name}\")\n",
    "        print(f\"Arguments: {output.function_call.arguments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# Define response structure\n",
    "class EventDetails(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: List[str]\n",
    "    location: str\n",
    "\n",
    "# Generate structured output\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Alice and Bob are meeting for a coding workshop at the library on Friday.\",\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"event_extraction\",\n",
    "            \"schema\": EventDetails.model_json_schema(),\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Parse structured response\n",
    "event_data = json.loads(response.output_text)\n",
    "print(json.dumps(event_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Built-in Tools\n",
    "\n",
    "### Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use web search tool\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"What are the latest developments in AI in 2025?\",\n",
    "    tools=[{\"type\": \"web_search_preview\"}]\n",
    ")\n",
    "\n",
    "print(response.output_text)\n",
    "\n",
    "# Access citations\n",
    "for output in response.output:\n",
    "    if hasattr(output, 'content'):\n",
    "        for content in output.content:\n",
    "            if hasattr(content, 'annotations'):\n",
    "                for annotation in content.annotations:\n",
    "                    if annotation.type == 'url_citation':\n",
    "                        print(f\"Source: {annotation.title}\")\n",
    "                        print(f\"URL: {annotation.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and search files (requires vector store setup)\n",
    "# First, upload a file\n",
    "# with open(\"sample_document.pdf\", \"rb\") as file:\n",
    "#     uploaded_file = client.files.create(file=file, purpose=\"assistants\")\n",
    "\n",
    "# Create vector store\n",
    "# vector_store = client.vector_stores.create(name=\"knowledge_base\")\n",
    "\n",
    "# Add file to vector store\n",
    "# client.vector_stores.files.create(\n",
    "#     vector_store_id=vector_store.id,\n",
    "#     file_id=uploaded_file.id\n",
    "# )\n",
    "\n",
    "# Search within uploaded files\n",
    "# response = client.responses.create(\n",
    "#     model=\"gpt-4o\",\n",
    "#     input=\"What are the key findings in the uploaded document?\",\n",
    "#     tools=[{\n",
    "#         \"type\": \"file_search\",\n",
    "#         \"vector_store_ids\": [vector_store.id],\n",
    "#         \"max_num_results\": 3\n",
    "#     }]\n",
    "# )\n",
    "\n",
    "# print(response.output_text)\n",
    "\n",
    "print(\"File search example - uncomment code above when you have files to upload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze images\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\"role\": \"user\", \"content\": \"Describe what you see in this image.\"},\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [{\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/PNG_transparency_demonstration_1.png/280px-PNG_transparency_demonstration_1.png\"\n",
    "            }]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streaming Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream responses in real-time\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Explain machine learning in simple terms.\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(\"Streaming response:\")\n",
    "for event in stream:\n",
    "    if hasattr(event, \"type\") and \"text.delta\" in event.type:\n",
    "        print(event.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Features\n",
    "\n",
    "### Background Mode (for reasoning models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use reasoning models with background processing\n",
    "response = client.responses.create(\n",
    "    model=\"o3-mini\",\n",
    "    input=\"Solve this complex math problem: Find the derivative of x^3 + 2x^2 - 5x + 3\",\n",
    "    reasoning={\"effort\": \"medium\"}\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "try:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=\"Hello world!\"\n",
    "    )\n",
    "    print(response.output_text)\n",
    "    \n",
    "except openai.RateLimitError:\n",
    "    print(\"Rate limit exceeded. Please try again later.\")\n",
    "except openai.APIError as e:\n",
    "    print(f\"API error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "1. **Use appropriate models**: Choose `gpt-4o` for complex tasks, `gpt-4o-mini` for simple operations\n",
    "2. **Manage conversation state**: Use `previous_response_id` for multi-turn conversations\n",
    "3. **Leverage built-in tools**: Web search and file search reduce development complexity\n",
    "4. **Structure outputs**: Use JSON schemas for consistent, parseable responses\n",
    "5. **Handle errors gracefully**: Implement proper error handling for production applications\n",
    "6. **Monitor usage**: Track API usage and costs in production environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migration from Chat Completions\n",
    "\n",
    "The Responses API is backward compatible with Chat Completions, making migration straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Chat Completions way\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-4o\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    "# )\n",
    "\n",
    "# New Responses API way\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Hello!\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Responses API provides a more powerful, unified interface for building sophisticated AI applications with less code and complexity. It combines orchestration logic and integrates built-in tools without requiring custom implementation, making it the preferred choice for new projects.\n",
    "\n",
    "Key advantages:\n",
    "- Simplified development experience\n",
    "- Built-in tools reduce boilerplate code\n",
    "- Automatic conversation state management\n",
    "- Enhanced function calling capabilities\n",
    "- Support for multimodal inputs and structured outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}