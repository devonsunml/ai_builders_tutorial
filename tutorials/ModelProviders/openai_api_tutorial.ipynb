{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Responses API: Complete Tutorial\n",
    "\n",
    "## Overview\n",
    "\n",
    "The OpenAI Responses API is a superset of Chat Completions, meaning everything you can do with Chat Completions can be done with the Responses API, plus additional features. This unified interface simplifies building AI applications with built-in tools, conversation management, and enhanced capabilities.\n",
    "\n",
    "### Key Features\n",
    "- **Simplified Interface**: Single API for complex interactions\n",
    "- **Built-in Tools**: Web search, file search, computer use\n",
    "- **Stateful Conversations**: Automatic conversation management\n",
    "- **Structured Outputs**: Type-safe responses with Pydantic\n",
    "- **Enhanced Function Calling**: Custom tool integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install required packages\n",
    "# !pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Machine minds awake,  \n",
       "Patterns dance in circuits bright‚Äî  \n",
       "Whispers of the code."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple text generation\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Write a haiku about artificial intelligence.\"\n",
    ")\n",
    "\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions vs Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To read a CSV file in Python, you can use several methods. Here are two common ways using built-in and external libraries:\n",
      "\n",
      "### Method 1: Using the `csv` module\n",
      "\n",
      "```python\n",
      "import csv\n",
      "\n",
      "# Specify the path to your CSV file\n",
      "csv_file_path = 'your_file.csv'\n",
      "\n",
      "# Open the file and read its contents\n",
      "with open(csv_file_path, mode='r', newline='') as file:\n",
      "    csv_reader = csv.reader(file)\n",
      "    \n",
      "    # Iterate over each row in the CSV\n",
      "    for row in csv_reader:\n",
      "        print(row)\n",
      "```\n",
      "\n",
      "### Method 2: Using `pandas`\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Specify the path to your CSV file\n",
      "csv_file_path = 'your_file.csv'\n",
      "\n",
      "# Read the CSV file using pandas\n",
      "df = pd.read_csv(csv_file_path)\n",
      "\n",
      "# Display the contents of the DataFrame\n",
      "print(df)\n",
      "```\n",
      "\n",
      "### Key Differences:\n",
      "- The `csv` module is part of Python's standard library and provides simple handling for CSV file reading.\n",
      "- `pandas` is an external library that provides more powerful data manipulation capabilities. If you need to perform more complex operations on your data, `pandas` is often the preferred choice.\n",
      "\n",
      "Make sure to install pandas if you're using the second method:\n",
      "\n",
      "```bash\n",
      "pip install pandas\n",
      "```\n",
      "\n",
      "These examples assume your CSV file is structured with rows of data separated by commas. Adjust the code if your file uses a different delimiter or has a header.\n"
     ]
    }
   ],
   "source": [
    "# Using instructions for system-level guidance\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=\"You are a helpful coding assistant. Always provide working code examples.\",\n",
    "    input=\"How do I read a CSV file in Python?\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conversation State Management\n",
    "\n",
    "### Manual State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of my last update, the population of Paris is approximately 2.1 million people within the city limits. However, the larger metropolitan area has a population of around 11 million. For the most current figures, it's always a good idea to check official statistics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build conversation manually\n",
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the population?\"}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=conversation\n",
    ")\n",
    "\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Python is a versatile, high-level programming language known for its readability, simplicity, and extensive libraries for various applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Python offers simplicity, readability, extensive libraries, community support, cross-platform compatibility, rapid development, strong integration capabilities, and versatility for multiple domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let OpenAI handle conversation state\n",
    "response1 = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"Tell me about Python programming in 20 words.\"\n",
    ")\n",
    "\n",
    "# Continue conversation using previous response ID\n",
    "response2 = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    previous_response_id=response1.id,\n",
    "    input=\"What are its main advantages in 20 words?\"\n",
    ")\n",
    "\n",
    "print(\"First response:\")\n",
    "display(Markdown(response1.output_text))\n",
    "print(\"\\nSecond response:\")\n",
    "display(Markdown(response2.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Function Calling\n",
    "\n",
    "Simple demo of OpenAI function calling - AI decides when to call your custom functions.\n",
    "\n",
    "**How it works:**\n",
    "1. Define a Python function  \n",
    "2. Describe it to OpenAI with a tool schema  \n",
    "3. AI automatically calls it when needed  \n",
    "4. You execute the function and see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ AI called: get_weather({\"city\":\"Tokyo\"})\n",
      "üìä Result: üå§Ô∏è Tokyo: 31¬∞C, Partly cloudy\n",
      "‚úÖ Function calling works!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(city):\n",
    "    \"\"\"Get weather using a simple API\"\"\"\n",
    "    try:\n",
    "        # Simple weather API that returns JSON\n",
    "        url = f\"https://wttr.in/{city}?format=j1\"\n",
    "        data = requests.get(url, timeout=5).json()\n",
    "        temp = data[\"current_condition\"][0][\"temp_C\"]\n",
    "        desc = data[\"current_condition\"][0][\"weatherDesc\"][0][\"value\"]\n",
    "        return f\"üå§Ô∏è {city}: {temp}¬∞C, {desc}\"\n",
    "    except:\n",
    "        return f\"üå§Ô∏è {city}: 22¬∞C, Sunny (demo data)\"\n",
    "\n",
    "# Define the tool for OpenAI\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get weather for a city\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"city\": {\"type\": \"string\"}},\n",
    "        \"required\": [\"city\"]\n",
    "    }\n",
    "}]\n",
    "\n",
    "# Call OpenAI with the tool\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"What's the weather in Tokyo?\",\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# Execute any function calls\n",
    "for output in response.output:\n",
    "    if hasattr(output, 'type') and output.type == 'function_call':\n",
    "        print(f\"ü§ñ AI called: {output.name}({output.arguments})\")\n",
    "        \n",
    "        # Execute the function\n",
    "        import json\n",
    "        args = json.loads(output.arguments)\n",
    "        result = get_weather(**args)\n",
    "        \n",
    "        print(f\"üìä Result: {result}\")\n",
    "        print(\"‚úÖ Function calling works!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Coding Workshop\",\n",
      "  \"date\": \"Friday\",\n",
      "  \"participants\": [\n",
      "    \"Alice\",\n",
      "    \"Bob\"\n",
      "  ],\n",
      "  \"location\": \"Library\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# Define response structure\n",
    "class EventDetails(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: List[str]\n",
    "    location: str\n",
    "\n",
    "# Get the schema and add required additionalProperties field\n",
    "schema = EventDetails.model_json_schema()\n",
    "schema[\"additionalProperties\"] = False\n",
    "\n",
    "# Generate structured output\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Alice and Bob are meeting for a coding workshop at the library on Friday.\",\n",
    "    # Define the output text format\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"event_extraction\",\n",
    "            \"schema\": schema,\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Parse structured response\n",
    "event_data = json.loads(response.output_text)\n",
    "print(json.dumps(event_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Built-in Tools\n",
    "\n",
    "### Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of August 2, 2025, the field of artificial intelligence (AI) has seen several significant developments:\n",
       "\n",
       "1. **U.S. SEC Establishes AI Task Force**: The U.S. Securities and Exchange Commission (SEC) announced the formation of a new AI task force to enhance innovation and efficiency within its operations. Valerie Szczepanik has been appointed as the SEC's first Chief AI Officer to lead this initiative. ([reuters.com](https://www.reuters.com/technology/us-securities-regulator-announces-ai-task-force-2025-08-01/?utm_source=openai))\n",
       "\n",
       "2. **China Proposes Global AI Cooperation Organization**: China has proposed creating an international organization to promote global cooperation on AI, aiming to provide an alternative to U.S.-led initiatives and foster inclusive development of the technology. Premier Li Qiang announced this at the World Artificial Intelligence Conference in Shanghai. ([reuters.com](https://www.reuters.com/world/china/china-proposes-new-global-ai-cooperation-organisation-2025-07-26/?utm_source=openai))\n",
       "\n",
       "3. **Meta Launches 'Superintelligence' Lab**: Meta has established a new division, Meta Superintelligence Labs, to centralize and accelerate its AI efforts. Alexandr Wang, former CEO of Scale AI, has been appointed as Chief AI Officer to lead this initiative, focusing on advancements in artificial general intelligence (AGI). ([reuters.com](https://www.reuters.com/business/meta-deepens-ai-push-with-superintelligence-lab-source-says-2025-06-30/?utm_source=openai))\n",
       "\n",
       "4. **Google Introduces 'AI Mode' in Search**: Google unveiled a new \"AI Mode\" in its search engine, allowing users to interact conversationally to receive expert-level answers. This feature integrates Google's Gemini 2.5 model and includes capabilities like automated ticket purchases and live video search functions. ([apnews.com](https://apnews.com/article/5b0cdc59870508dab856227185cb8e23?utm_source=openai))\n",
       "\n",
       "5. **Advancements in AI Agents**: AI agents are evolving from simple co-pilots to sophisticated autonomous systems, referred to as \"agentic AI.\" These agents can analyze data, understand context, and make independent decisions to achieve user-defined goals, transforming industries such as healthcare, finance, law, and retail. ([ft.com](https://www.ft.com/content/3e862e23-6e2c-4670-a68c-e204379fe01f?utm_source=openai))\n",
       "\n",
       "These developments highlight the rapid progress and diverse applications of AI across various sectors.\n",
       "\n",
       "\n",
       "## Recent AI Developments in 2025:\n",
       "- [US securities regulator announces AI task force](https://www.reuters.com/technology/us-securities-regulator-announces-ai-task-force-2025-08-01/?utm_source=openai)\n",
       "- [China proposes new global AI cooperation organisation](https://www.reuters.com/world/china/china-proposes-new-global-ai-cooperation-organisation-2025-07-26/?utm_source=openai)\n",
       "- [Meta deepens AI push with 'Superintelligence' lab, source says](https://www.reuters.com/business/meta-deepens-ai-push-with-superintelligence-lab-source-says-2025-06-30/?utm_source=openai) "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: US securities regulator announces AI task force\n",
      "URL: https://www.reuters.com/technology/us-securities-regulator-announces-ai-task-force-2025-08-01/?utm_source=openai\n",
      "Source: China proposes new global AI cooperation organisation\n",
      "URL: https://www.reuters.com/world/china/china-proposes-new-global-ai-cooperation-organisation-2025-07-26/?utm_source=openai\n",
      "Source: Meta deepens AI push with 'Superintelligence' lab, source says\n",
      "URL: https://www.reuters.com/business/meta-deepens-ai-push-with-superintelligence-lab-source-says-2025-06-30/?utm_source=openai\n",
      "Source: Google's unleashes 'AI Mode' in the next phase of its journey to change search\n",
      "URL: https://apnews.com/article/5b0cdc59870508dab856227185cb8e23?utm_source=openai\n",
      "Source: AI agents: from co-pilot to autopilot\n",
      "URL: https://www.ft.com/content/3e862e23-6e2c-4670-a68c-e204379fe01f?utm_source=openai\n",
      "Source: US securities regulator announces AI task force\n",
      "URL: https://www.reuters.com/technology/us-securities-regulator-announces-ai-task-force-2025-08-01/?utm_source=openai\n",
      "Source: China proposes new global AI cooperation organisation\n",
      "URL: https://www.reuters.com/world/china/china-proposes-new-global-ai-cooperation-organisation-2025-07-26/?utm_source=openai\n",
      "Source: Meta deepens AI push with 'Superintelligence' lab, source says\n",
      "URL: https://www.reuters.com/business/meta-deepens-ai-push-with-superintelligence-lab-source-says-2025-06-30/?utm_source=openai\n"
     ]
    }
   ],
   "source": [
    "# Use web search tool\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"What are the latest developments in AI in 2025? give me top 5 sources only\",\n",
    "    tools=[{\"type\": \"web_search_preview\"}]\n",
    ")\n",
    "\n",
    "display(Markdown(response.output_text))\n",
    "\n",
    "# Access citations\n",
    "for output in response.output:\n",
    "    if hasattr(output, 'content'):\n",
    "        for content in output.content:\n",
    "            if hasattr(content, 'annotations'):\n",
    "                for annotation in content.annotations:\n",
    "                    if annotation.type == 'url_citation':\n",
    "                        print(f\"Source: {annotation.title}\")\n",
    "                        print(f\"URL: {annotation.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded: file-C4XCANNzS1AJkRSkQB2raw\n",
      "Vector store created: vs_688dbc4530608191bf2c80a71ccf2c49\n",
      "File added to vector store. Status: in_progress\n",
      "File processing status: completed\n",
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "AI agents are systems designed to autonomously accomplish tasks on behalf of users. Key characteristics include leveraging a Large Language Model (LLM) for decision-making and workflow execution, accessing various tools to interact with external systems, and operating under clearly defined guidelines to ensure reliability. They are ideal for complex decision-making, handling unstructured data, and managing tasks where rule-based systems are insufficient."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload and search files (requires vector store setup)\n",
    "# First, upload a file with correct path\n",
    "file_path = \"a-practical-guide-to-building-agents.pdf\"\n",
    "with open(file_path, \"rb\") as file:\n",
    "    uploaded_file = client.files.create(file=file, purpose=\"assistants\")\n",
    "\n",
    "print(f\"File uploaded: {uploaded_file.id}\")\n",
    "\n",
    "# Create vector store\n",
    "vector_store = client.vector_stores.create(name=\"knowledge_base\")\n",
    "print(f\"Vector store created: {vector_store.id}\")\n",
    "\n",
    "# Add file to vector store\n",
    "file_batch = client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=uploaded_file.id\n",
    ")\n",
    "\n",
    "print(f\"File added to vector store. Status: {file_batch.status}\")\n",
    "\n",
    "# Wait a moment for processing (in production, you'd check the status)\n",
    "import time\n",
    "time.sleep(5)  # Wait a bit longer for processing\n",
    "\n",
    "# Check if the file is processed\n",
    "file_status = client.vector_stores.files.retrieve(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=uploaded_file.id\n",
    ")\n",
    "print(f\"File processing status: {file_status.status}\")\n",
    "\n",
    "# Search within uploaded files using correct tool structure\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"What are AI Agents based on the uploaded document? Provide a detailed explanation of their key characteristics and capabilities within 100 words.\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store.id],\n",
    "        \"max_num_results\": 5\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(\"Response:\")\n",
    "display(Markdown(response.output_text))\n",
    "\n",
    "# Also show any citations if available\n",
    "for output in response.output:\n",
    "    if hasattr(output, 'content'):\n",
    "        for content_item in output.content:\n",
    "            if hasattr(content_item, 'annotations'):\n",
    "                for annotation in content_item.annotations:\n",
    "                    if hasattr(annotation, 'file_citation'):\n",
    "                        print(f\"\\nSource: File {annotation.file_citation.file_id}\")\n",
    "                        print(f\"Quote: {annotation.file_citation.quote}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image being analyzed:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 200
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Image loaded successfully!\n",
      "\n",
      "==================================================\n",
      "AI Analysis:\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The image shows the Python programming language logo, which consists of two stylized snakes intertwined in a yin-yang pattern. One snake is blue, on the left and top side, with its head pointing to the left. The other snake is yellow, positioned on the right and bottom side, with its head pointing to the right. Each snake has a dot resembling an eye near its head. The overall design is smooth and symmetrical."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze images\n",
    "from IPython.display import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Image URL to analyze - using a clear JPG image\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Python-logo-notext.svg/110px-Python-logo-notext.svg.png\"\n",
    "\n",
    "# Display the image first\n",
    "print(\"Image being analyzed:\")\n",
    "try:\n",
    "    # Download and display the image with better error handling\n",
    "    response_img = requests.get(image_url, timeout=10)\n",
    "    response_img.raise_for_status()  # Raise an exception for bad status codes\n",
    "    \n",
    "    # Create image object and display\n",
    "    img = Image(data=response_img.content, width=200)  # Set width for better display\n",
    "    display(img)\n",
    "    print(\"‚úÖ Image loaded successfully!\")\n",
    "    \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"‚ùå Network error loading image: {e}\")\n",
    "    print(f\"Image URL: {image_url}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error displaying image: {e}\")\n",
    "    print(f\"Image URL: {image_url}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"AI Analysis:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Analyze the image with OpenAI\n",
    "try:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=[\n",
    "            {\"role\": \"user\", \"content\": \"Describe what you see in this image in detail.\"},\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [{\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": image_url\n",
    "                }]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    display(Markdown(response.output_text))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error analyzing image with OpenAI: {e}\")\n",
    "    print(\"Make sure your OpenAI API key is set correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streaming Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response:\n",
      "Machine learning is a type of artificial intelligence that enables computers to learn from data and improve their performance over time without being explicitly programmed. Instead of following fixed rules, machines analyze patterns in data, make predictions, and adapt based on new information. For example, a recommendation system suggests movies by learning your preferences from past choices. Overall, it's about teaching computers to think and learn like humans do, using examples and experience to solve problems."
     ]
    }
   ],
   "source": [
    "# Stream responses in real-time\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"Explain machine learning in simple terms within 100 words.\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(\"Streaming response:\")\n",
    "for event in stream:\n",
    "    if hasattr(event, \"type\") and \"text.delta\" in event.type:\n",
    "        print(event.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Features\n",
    "\n",
    "### Background Mode (for reasoning models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the derivative of the function f(x) = x¬≥ + 2x¬≤ ‚Äì 5x + 3, we'll differentiate each term separately using the power rule. The power rule states that the derivative of x^n is n¬∑x^(n-1).\n",
      "\n",
      "1. For x¬≥, the derivative is 3x¬≤.\n",
      "2. For 2x¬≤, the derivative is 2 √ó 2x = 4x.\n",
      "3. For ‚Äì5x, the derivative is ‚Äì5.\n",
      "4. The derivative of the constant 3 is 0.\n",
      "\n",
      "Putting these together, the derivative f‚Äâ'(x) is:\n",
      "\n",
      "‚ÄÉ‚ÄÉf‚Äâ'(x) = 3x¬≤ + 4x ‚Äì 5.\n"
     ]
    }
   ],
   "source": [
    "# Use reasoning models with background processing\n",
    "response = client.responses.create(\n",
    "    model=\"o3-mini\",\n",
    "    input=\"Solve this complex math problem: Find the derivative of x^3 + 2x^2 - 5x + 3\",\n",
    "    reasoning={\"effort\": \"medium\"}\n",
    ")\n",
    "\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "try:\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4o\",\n",
    "        input=\"Hello world!\"\n",
    "    )\n",
    "    print(response.output_text)\n",
    "    \n",
    "except openai.RateLimitError:\n",
    "    print(\"Rate limit exceeded. Please try again later.\")\n",
    "except openai.APIError as e:\n",
    "    print(f\"API error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "1. **Use appropriate models**: Choose `gpt-4o` for complex tasks, `gpt-4o-mini` for simple operations\n",
    "2. **Manage conversation state**: Use `previous_response_id` for multi-turn conversations\n",
    "3. **Leverage built-in tools**: Web search and file search reduce development complexity\n",
    "4. **Structure outputs**: Use JSON schemas for consistent, parseable responses\n",
    "5. **Handle errors gracefully**: Implement proper error handling for production applications\n",
    "6. **Monitor usage**: Track API usage and costs in production environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migration from Chat Completions\n",
    "\n",
    "The Responses API is backward compatible with Chat Completions, making migration straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Chat Completions way\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"gpt-4o\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    "# )\n",
    "\n",
    "# New Responses API way\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Hello!\"\n",
    ")\n",
    "\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Responses API provides a more powerful, unified interface for building sophisticated AI applications with less code and complexity. It combines orchestration logic and integrates built-in tools without requiring custom implementation, making it the preferred choice for new projects.\n",
    "\n",
    "Key advantages:\n",
    "- Simplified development experience\n",
    "- Built-in tools reduce boilerplate code\n",
    "- Automatic conversation state management\n",
    "- Enhanced function calling capabilities\n",
    "- Support for multimodal inputs and structured outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
