{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nosana AI Inference with OpenAI SDK\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial shows how to use the OpenAI SDK to connect directly to AI models deployed on [Nosana](https://nosana.com)'s GPU network. Nosana services expose OpenAI-compatible endpoints, making it easy to integrate with existing AI applications.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Connect OpenAI SDK to Nosana AI endpoints\n",
    "- Generate text with different parameters\n",
    "- Use streaming for real-time responses\n",
    "- Process multiple requests efficiently\n",
    "- Build practical AI workflows\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- Basic understanding of AI APIs\n",
    "- A deployed Nosana AI service URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un comment to install required packages\n",
    "# !pip install openai requests pillow matplotlib python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Nosana AI Service\n",
    "\n",
    "The Nosana service URL is loaded from your `.env` file. Most Nosana deployments expose OpenAI-compatible APIs at `/v1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Connected to Nosana AI service\n",
      "üìç Endpoint: https://4oetidyuynh82uhbxwfmgmkyniw3fvyrz92eqtkwj6yb.node.k8s.prd.nos.ci//v1\n",
      "ü§ñ Model: DeepSeek-R1-Distill-Qwen-1.5B\n"
     ]
    }
   ],
   "source": [
    "# Load Nosana service URL from environment variables\n",
    "NOSANA_BASE_URL = os.getenv(\"NOSANA_BASE_URL\")\n",
    "MODEL_NAME = \"DeepSeek-R1-Distill-Qwen-1.5B\"  # Replace with your model name\n",
    "\n",
    "if not NOSANA_BASE_URL:\n",
    "    raise ValueError(\"NOSANA_BASE_URL not found in environment variables. Please check your .env file.\")\n",
    "\n",
    "# Initialize OpenAI client with Nosana endpoint\n",
    "client = OpenAI(\n",
    "    base_url=f\"{NOSANA_BASE_URL}/v1\",\n",
    "    api_key=\"nosana-key\"  # Many Nosana services don't require real API keys\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Connected to Nosana AI service\")\n",
    "print(f\"üìç Endpoint: {NOSANA_BASE_URL}/v1\")\n",
    "print(f\"ü§ñ Model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Available models:\n",
      "  ‚Ä¢ DeepSeek-R1-Distill-Qwen-1.5B\n"
     ]
    }
   ],
   "source": [
    "# Check available models (optional)\n",
    "try:\n",
    "    models = client.models.list()\n",
    "    print(\"\\nüìã Available models:\")\n",
    "    for model in models.data:\n",
    "        print(f\"  ‚Ä¢ {model.id}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è Could not list models: {e}\")\n",
    "    print(\"This is normal for some Nosana deployments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing: Explain what Nosana is in simple terms.\n",
      "\n",
      "üìù Response:\n",
      "Okay, so I need to explain what Nosana is in simple terms. Hmm, I'm not exactly sure what Nosana is, but I've heard the name before. Maybe it's a video game? I'll try to break it down.\n",
      "\n",
      "First, I remember that Nosana has something to do with space exploration or maybe something related to space travel. It's probably a game where you play as a crew member. So maybe it's like a role-playing game where you're part of a space mission.\n",
      "\n",
      "I think about the crew members. They would probably have to deal with things like spacewalks, repairs, and maybe even friendly or hostile alien creatures. That makes sense because in space, you have to be prepared for various situations.\n",
      "\n",
      "I also recall that there's a lot of technology involved. Maybe it's like a spaceship that you pilot, but the spaceship is actually made up of different parts. Each part could represent different systems or systems within the spaceship. That sounds a bit complicated, but it's just a way to model the spaceship.\n",
      "\n",
      "Another thing I remember is that the game uses a lot of special items or tech items. These might be things like communication devices, medical equipment, or maybe even something that helps with navigation. These items would be essential for the crew to survive and operate effectively.\n",
      "\n",
      "I think about the players themselves. They would have to make choices that affect the spaceship's operations. For example, they might choose to repair a part of the ship, send a\n"
     ]
    }
   ],
   "source": [
    "# Simple text generation\n",
    "def generate_text(prompt, max_tokens=300, temperature=0.7, stream=False):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            stream=stream\n",
    "        )\n",
    "        \n",
    "        if stream:\n",
    "            return response  # Return generator for streaming\n",
    "        else:\n",
    "            return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test basic generation\n",
    "test_prompt = \"Explain what Nosana is in simple terms.\"\n",
    "print(f\"üß™ Testing: {test_prompt}\")\n",
    "print(\"\\nüìù Response:\")\n",
    "response = generate_text(test_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Streaming response for: Write a detailed explanation of how blockchain technology works\n",
      "\n",
      "============================================================\n",
      "Okay, so I need to explain how blockchain technology works in detail. I remember that blockchain is the technology used in Bitcoin, but I'm a bit fuzzy on the exact steps. Let me try to break it down.\n",
      "\n",
      "First, I think blockchain is a distributed ledger, right? It's like a digital document that's secure and tamper-proof. But how does it work exactly? I remember something about nodes, which are computers or other blockchain systems. So, nodes exchange blocks of data, which are like records of transactions. But how does this exchange happen?\n",
      "\n",
      "I think it's through something called a proof-of-work mechanism. That means each node has to do some computational work to validate the block. So, the more work you do, the more you get paid. That makes sense because it adds a layer of security since it's hard to cheat.\n",
      "\n",
      "Wait, but how does the proof-of-work work in detail? I think it involves creating a hash, which is like a digital fingerprint of the data. Then, the hash has to be below a certain threshold to be considered valid. So, the node has to find a hash that meets this condition, which requires some computational effort.\n",
      "\n",
      "Once a node validates a block, it gets rewarded with cryptocurrency. But how does that reward work? I think it's based on the amount of work the node did. So, the more work, the more rewards. But I'm not sure how this incentivizes honest nodes over malicious ones.\n",
      "\n",
      "Then, when a block is added to the main chain, it's called a consensus mechanism. I think this is where nodes agree on the order of blocks. If a node adds a block that's inconsistent with the main chain, it's considered malicious. But how does this happen? Maybe through a proof-of-work that's harder than the main chain.\n",
      "\n",
      "Once the main chain is agreed upon, the network can validate transactions. This is where the consensus mechanism comes into play again. If a node validates a transaction against the main chain, it's considered honest. But if it's inconsistent, it's considered malicious.\n",
      "\n",
      "Once a transaction is validated, it's added to the blockchain. But how does this happen in real-time? I think it's through a process called proof-of-work, where the node has to solve a complex problem to add the transaction to the chain. This adds a layer of security because it's computationally intensive and hard to cheat.\n",
      "\n",
      "I'm a bit confused about the proof-of-work process. How exactly does the node find a hash that's below the target? I think it's a process where the node generates a random input, computes the hash, and if it's below the target, it's considered valid. But how does this balance between honest and malicious nodes? Maybe the honest nodes do more work, so they get more rewards, while malicious nodes do less.\n",
      "\n",
      "Also, how does the network reach consensus? I think it's through a process called proof-of-stake, where\n",
      "============================================================\n",
      "‚úÖ Streaming complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Streaming for real-time output\n",
    "def stream_response(prompt, max_tokens=500, temperature=0.7):\n",
    "    print(f\"üìù Streaming response for: {prompt}\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        stream = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        full_response = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                content = chunk.choices[0].delta.content\n",
    "                full_response += content\n",
    "                print(content, end=\"\", flush=True)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úÖ Streaming complete!\\n\")\n",
    "        return full_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example streaming\n",
    "stream_prompt = \"Write a detailed explanation of how blockchain technology works\"\n",
    "streamed_text = stream_response(stream_prompt, max_tokens=600, temperature=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Context & Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Multi-turn Conversation Example:\n",
      "\n",
      "üë§ User: Hi! Can you explain what machine learning is?\n",
      "ü§ñ Assistant: Okay, so I need to explain what machine learning is. Hmm, where do I start? I've heard about it a lot, but I'm not exactly sure what it really is. Let me think. I know it has something to do with computers learning from data, but I'm not entirely clear on the specifics.\n",
      "\n",
      "Maybe I should break it down. From what I remember, machine learning is a type of artificial intelligence, right? So AI is about machines doing tasks like speech recognition or computer vision, but I think machine learning is a subset of that. But how exactly does it work? Is it about algorithms?\n",
      "\n",
      "I think there are different types of machine learning, like supervised, unsupervised, and reinforcement learning. Wait, what's the difference between them? I remember supervised learning involves labeled data, so the model knows the correct answers and learns from them. Unsupervised is when there's no labeled data, and it finds patterns on its own. And reinforcement learning is where the model learns by interacting with an environment and receiving rewards or penalties. That makes sense because I've seen games like AlphaGo where AI learns through trial and error.\n",
      "\n",
      "But how do these algorithms actually work? Like, what's the process of training a model? I think it involves feeding the data into the model, which adjusts its internal parameters to minimize errors. There must be some kind of optimization process, maybe gradient descent, to find the best parameters.\n",
      "\n",
      "I also remember something about feature engineering. That's\n",
      "\n",
      "üë§ User: That's interesting! Can you give me a real-world example?\n",
      "ü§ñ Assistant: Okay, so the user just asked for a real-world example of machine learning. I need to provide a clear and relatable example that someone without a technical background can understand.\n",
      "\n",
      "First, I should connect machine learning to something they know, like everyday technology. Maybe something like recommendation systems or image processing. These are areas where people have used AI in their daily lives.\n",
      "\n",
      "I should explain how machine learning works in a simple way. Maybe start with a scenario they can visualize, like a recommendation engine for a streaming service. The user might not be familiar with the technical terms, so I should avoid jargon as much as possible.\n",
      "\n",
      "Breaking it down into steps makes it easier to follow. I'll outline how the system collects data, processes it, trains the model, and then applies it. Ending with how it benefits society shows the practical impact.\n",
      "\n",
      "I should also highlight the benefits of machine learning, like personalized experiences and efficiency, to make it seem relevant and useful. Keeping the language simple and conversational will help the user grasp the concept without feeling overwhelmed.\n",
      "</think>\n",
      "\n",
      "Sure! Let‚Äôs break it down with a simple, real-world example.\n",
      "\n",
      "Imagine you're using an app that tells you what your friends might like next on your phone. This is a recommendation system. Machine learning is the technology behind it. Here's how it works:\n",
      "\n",
      "1. **Collect Data**: The app collects data about what your friends have liked in the past. This could be based on their viewing history, genre preferences, or even\n",
      "\n",
      "üë§ User: How does that relate to what you explained earlier?\n",
      "ü§ñ Assistant: Okay, so I'm trying to understand how machine learning relates to the recommendation system example I just thought of. Let me go through it step by step.\n",
      "\n",
      "First, I know that machine learning is a subset of AI that allows computers to learn from data. It's about developing algorithms that can improve their performance as they are exposed to more data. The key here is that the models learn without being explicitly programmed.\n",
      "\n",
      "In the recommendation system, the app uses this learning to predict what a friend might like. So, the data collected is about the user's viewing history and preferences. This data is like the training data that the machine learning model uses to make predictions.\n",
      "\n",
      "Now, how does the model actually learn? I remember that there's something called feature engineering, where the data is transformed into features that the model can use. In this case, features might include things like the time of day, mood, or the genre of the content the user has been watching.\n",
      "\n",
      "Then there's the training process, which involves feeding this data into the machine learning algorithm. The algorithm adjusts its internal parameters to minimize errors, which are differences between the predicted and actual recommendations. This adjustment is where the optimization happens, maybe using methods like gradient descent.\n",
      "\n",
      "I also remember the concept of overfitting, where the model might perform well on the training data but poorly on new, unseen data. Regularization is a technique used to prevent this by adding constraints to the model, making it more generalizable.\n",
      "\n",
      "So, putting it all\n",
      "\n",
      "üìä Conversation length: 6 messages\n"
     ]
    }
   ],
   "source": [
    "# Multi-turn conversation with context\n",
    "def have_conversation(messages, new_message, max_tokens=300, temperature=0.7):\n",
    "    # Add new message to conversation\n",
    "    messages.append({\"role\": \"user\", \"content\": new_message})\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        assistant_message = response.choices[0].message.content\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "        \n",
    "        return assistant_message, messages\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", messages\n",
    "\n",
    "# Start a conversation about AI\n",
    "conversation = []\n",
    "\n",
    "print(\"üí¨ Multi-turn Conversation Example:\\n\")\n",
    "\n",
    "# Turn 1\n",
    "response1, conversation = have_conversation(\n",
    "    conversation, \n",
    "    \"Hi! Can you explain what machine learning is?\"\n",
    ")\n",
    "print(\"üë§ User: Hi! Can you explain what machine learning is?\")\n",
    "print(f\"ü§ñ Assistant: {response1}\\n\")\n",
    "\n",
    "# Turn 2\n",
    "response2, conversation = have_conversation(\n",
    "    conversation, \n",
    "    \"That's interesting! Can you give me a real-world example?\"\n",
    ")\n",
    "print(\"üë§ User: That's interesting! Can you give me a real-world example?\")\n",
    "print(f\"ü§ñ Assistant: {response2}\\n\")\n",
    "\n",
    "# Turn 3\n",
    "response3, conversation = have_conversation(\n",
    "    conversation, \n",
    "    \"How does that relate to what you explained earlier?\"\n",
    ")\n",
    "print(\"üë§ User: How does that relate to what you explained earlier?\")\n",
    "print(f\"ü§ñ Assistant: {response3}\\n\")\n",
    "\n",
    "print(f\"üìä Conversation length: {len(conversation)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Batch Processing: Summarizing 4 articles\n",
      "\n",
      "üìÑ Processing 1/4: Nosana is building a decentralized GPU network tha...\n",
      "üìÑ Processing 2/4: Blockchain technology has evolved beyond cryptocur...\n",
      "üìÑ Processing 3/4: The demand for GPU computing has exploded with the...\n",
      "üìÑ Processing 4/4: Decentralized infrastructure offers several advant...\n",
      "\n",
      "üìä Results:\n",
      "================================================================================\n",
      "\n",
      "1. Original: Nosana is building a decentralized GPU network that makes AI compute more access...\n",
      "    Summary: Okay, so I need to summarize the given text into one clear sentence. Let me read through the text again to make sure I understand it properly.\n",
      "\n",
      "The text says, \"Nosana is building a decentralized GPU network that makes AI compute more accessible and affordable. The platform allows anyone to rent GPU power from a distributed network of providers, reducing costs and increasing availability for AI developers.\"\n",
      "\n",
      "Alright, so the main points are:\n",
      "\n",
      "1. Nosana is creating a decentralized GPU network.\n",
      "2. This network aims\n",
      "\n",
      "2. Original: Blockchain technology has evolved beyond cryptocurrencies to enable new forms of...\n",
      "    Summary: Alright, so I need to summarize this text into one clear sentence. Let me read through it again to make sure I understand what it's saying.\n",
      "\n",
      "The text mentions that blockchain technology has evolved beyond just cryptocurrencies to enable new forms of decentralized computing. It specifically talks about smart contracts that can manage resource allocation, payments, and service level agreements in distributed networks.\n",
      "\n",
      "Hmm, so the main points are: blockchain technology has expanded beyond crypto to other uses, smart contracts are a key part of this, and they\n",
      "\n",
      "3. Original: The demand for GPU computing has exploded with the rise of AI applications. Trad...\n",
      "    Summary: Okay, so I need to summarize this text into one clear sentence. Let me read through it again to make sure I understand it properly.\n",
      "\n",
      "The text says that the demand for GPU computing has exploded because of the rise in AI applications. Traditional cloud providers usually don't have enough hardware or are expensive, so they're looking for alternatives. These alternatives can use unused hardware from various sources to make computing more efficient and cost-effective.\n",
      "\n",
      "Hmm, so the main points are: GPU computing, AI applications, explosion\n",
      "\n",
      "4. Original: Decentralized infrastructure offers several advantages including censorship resi...\n",
      "    Summary: Okay, so I need to summarize this text into one clear sentence. Let me read through it again to make sure I understand all the key points.\n",
      "\n",
      "The text says that decentralized infrastructure offers several advantages, specifically censorship resistance, reduced single points of failure, and competitive pricing through open markets. These benefits are especially important for AI workloads that need a lot of computational resources.\n",
      "\n",
      "Hmm, so the main points are: decentralization makes things more resistant to censorship, less vulnerable to single points of failure, and\n"
     ]
    }
   ],
   "source": [
    "# Process multiple texts efficiently\n",
    "def batch_process(texts, task_instruction, max_tokens=200, temperature=0.3):\n",
    "    results = []\n",
    "    \n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f\"üìÑ Processing {i}/{len(texts)}: {text[:50]}...\")\n",
    "        \n",
    "        prompt = f\"{task_instruction}\\n\\nText: {text}\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=temperature\n",
    "            )\n",
    "            \n",
    "            result = response.choices[0].message.content\n",
    "            results.append({\n",
    "                \"index\": i,\n",
    "                \"original\": text,\n",
    "                \"processed\": result\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"index\": i,\n",
    "                \"original\": text,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Summarize multiple articles\n",
    "articles = [\n",
    "    \"Nosana is building a decentralized GPU network that makes AI compute more accessible and affordable. The platform allows anyone to rent GPU power from a distributed network of providers, reducing costs and increasing availability for AI developers.\",\n",
    "    \n",
    "    \"Blockchain technology has evolved beyond cryptocurrencies to enable new forms of decentralized computing. Smart contracts can automatically manage resource allocation, payments, and service level agreements in distributed networks.\",\n",
    "    \n",
    "    \"The demand for GPU computing has exploded with the rise of AI applications. Traditional cloud providers often have limited availability and high costs, creating opportunities for decentralized alternatives that can utilize idle hardware from various sources.\",\n",
    "    \n",
    "    \"Decentralized infrastructure offers several advantages including censorship resistance, reduced single points of failure, and more competitive pricing through open markets. These benefits are particularly valuable for AI workloads that require significant computational resources.\"\n",
    "]\n",
    "\n",
    "task = \"Summarize this text in one clear sentence:\"\n",
    "\n",
    "print(f\"üîÑ Batch Processing: Summarizing {len(articles)} articles\\n\")\n",
    "summaries = batch_process(articles, task, max_tokens=100, temperature=0.2)\n",
    "\n",
    "print(\"\\nüìä Results:\")\n",
    "print(\"=\" * 80)\n",
    "for summary in summaries:\n",
    "    if \"error\" in summary:\n",
    "        print(f\"\\n{summary['index']}. Error: {summary['error']}\")\n",
    "    else:\n",
    "        print(f\"\\n{summary['index']}. Original: {summary['original'][:80]}...\")\n",
    "        print(f\"    Summary: {summary['processed']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices & Tips\n",
    "\n",
    "### Optimizing Requests\n",
    "- **Temperature Settings**: Use 0.1-0.3 for factual tasks, 0.7-0.9 for creative tasks\n",
    "- **Token Limits**: Set appropriate max_tokens to avoid unnecessary costs\n",
    "- **Batch Processing**: Group similar requests to maximize efficiency\n",
    "- **Caching**: Store responses for repeated queries\n",
    "\n",
    "### Performance Tips\n",
    "- Use streaming for long responses to improve perceived speed\n",
    "- Monitor response times and adjust timeout settings\n",
    "- Consider prompt length impact on processing time\n",
    "- Test different model configurations for your use case\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've learned how to:\n",
    "- ‚úÖ **Connect OpenAI SDK to Nosana endpoints** for seamless integration\n",
    "- ‚úÖ **Generate text with various parameters** for different use cases\n",
    "- ‚úÖ **Use streaming responses** for better user experience\n",
    "- ‚úÖ **Maintain conversation context** across multiple turns\n",
    "- ‚úÖ **Process batches efficiently** for high-volume applications\n",
    "- ‚úÖ **Build complete workflows** for real-world applications\n",
    "\n",
    "üöÄ **You're now ready to build powerful AI applications using Nosana's GPU network with the familiar OpenAI SDK!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
