{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic Claude API Tutorial\n",
    "\n",
    "This comprehensive tutorial covers essential concepts for working with Anthropic's Claude API, including the latest Claude 4 models.\n",
    "\n",
    "## What You'll Learn\n",
    "- Setup and authentication\n",
    "- Basic text generation with Claude 4 models\n",
    "- Streaming responses for real-time interaction\n",
    "- Vision capabilities for image analysis\n",
    "- Tool use (function calling)\n",
    "- Async operations for performance\n",
    "- Error handling and best practices\n",
    "\n",
    "## Claude 4 Models Overview\n",
    "\n",
    "**Claude 4 Opus** (`claude-opus-4-20250514`): Most capable model for complex reasoning\n",
    "- $15/$75 per million tokens (input/output)\n",
    "- Best for: Complex coding, research, advanced analysis\n",
    "\n",
    "**Claude 4 Sonnet** (`claude-sonnet-4-20250514`): Balanced performance and efficiency\n",
    "- $3/$15 per million tokens (input/output) \n",
    "- Best for: Production applications, coding, general tasks\n",
    "\n",
    "**Claude 3.5 Haiku** (`claude-3-5-haiku-20241022`): Fastest and most cost-effective\n",
    "- $0.80/$4 per million tokens (input/output)\n",
    "- Best for: Real-time chat, content moderation, simple tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install anthropic python-dotenv pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Authentication and Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import anthropic\n",
    "import base64\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize client with API key\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    # If no env var, you can pass directly: api_key=\"your-key-here\"\n",
    ")\n",
    "\n",
    "print(\"Claude API client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Text Generation with Claude 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_chat(prompt, model=\"claude-sonnet-4-20250514\"):\n",
    "    \"\"\"Basic text generation with Claude\"\"\"\n",
    "    try:\n",
    "        message = client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=1000,\n",
    "            temperature=0.7,\n",
    "            system=\"You are a helpful AI assistant.\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "response = basic_chat(\"Explain machine learning in simple terms\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Streaming Responses for Real-time Interaction\n",
    "\n",
    "Streaming reduces perceived latency by showing responses as they're generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_response(prompt):\n",
    "    \"\"\"Stream Claude's response in real-time\"\"\"\n",
    "    try:\n",
    "        with client.messages.stream(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=1000,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        ) as stream:\n",
    "            for text in stream.text_stream:\n",
    "                print(text, end=\"\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Streaming error: {e}\")\n",
    "\n",
    "# Example usage\n",
    "print(\"Streaming response:\")\n",
    "stream_response(\"Write a short poem about artificial intelligence\")\n",
    "print(\"\\n\\nStreaming complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vision Capabilities - Image Analysis\n",
    "\n",
    "Claude can analyze images and extract information from visual content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image(image_path, prompt=\"Describe this image in detail\"):\n",
    "    \"\"\"Analyze an image using Claude's vision capabilities\"\"\"\n",
    "    try:\n",
    "        # Read and encode image\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            image_data = base64.b64encode(image_file.read()).decode()\n",
    "        \n",
    "        message = client.messages.create(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=1000,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"image/jpeg\",\n",
    "                                \"data\": image_data\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    except Exception as e:\n",
    "        return f\"Vision error: {str(e)}\"\n",
    "\n",
    "# Example usage (replace with actual image path)\n",
    "# response = analyze_image(\"path/to/your/image.jpg\", \"What objects do you see?\")\n",
    "# print(response)\n",
    "print(\"Vision analysis function ready (provide image path to use)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Tool Use (Function Calling)\n",
    "\n",
    "Enable Claude to call external functions and tools for enhanced capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def get_weather(location):\n",
    "    \"\"\"Mock weather function\"\"\"\n",
    "    return f\"The weather in {location} is sunny, 22Â°C\"\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"Safe calculator function\"\"\"\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except:\n",
    "        return \"Invalid expression\"\n",
    "\n",
    "def chat_with_tools(prompt):\n",
    "    \"\"\"Chat with Claude using tools\"\"\"\n",
    "    tools = [\n",
    "        {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a location\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City name\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Perform mathematical calculations\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Mathematical expression\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=1000,\n",
    "        tools=tools,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return message\n",
    "\n",
    "# Example usage\n",
    "response = chat_with_tools(\"What's the weather in Paris and calculate 15 * 7?\")\n",
    "print(f\"Response type: {response.content[0].type}\")\n",
    "if hasattr(response.content[0], 'text'):\n",
    "    print(f\"Text: {response.content[0].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Async Operations for Better Performance\n",
    "\n",
    "Use async operations to handle multiple requests concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import AsyncAnthropic\n",
    "\n",
    "# Initialize async client\n",
    "async_client = AsyncAnthropic(\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    ")\n",
    "\n",
    "async def async_chat(prompt, model=\"claude-sonnet-4-20250514\"):\n",
    "    \"\"\"Async chat function\"\"\"\n",
    "    message = await async_client.messages.create(\n",
    "        model=model,\n",
    "        max_tokens=500,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "async def multiple_requests():\n",
    "    \"\"\"Handle multiple requests concurrently\"\"\"\n",
    "    prompts = [\n",
    "        \"Explain quantum computing\",\n",
    "        \"What is blockchain?\", \n",
    "        \"Define machine learning\"\n",
    "    ]\n",
    "    \n",
    "    tasks = [async_chat(prompt) for prompt in prompts]\n",
    "    responses = await asyncio.gather(*tasks)\n",
    "    \n",
    "    for i, response in enumerate(responses):\n",
    "        print(f\"Response {i+1}: {response[:100]}...\\n\")\n",
    "\n",
    "# Run async example\n",
    "print(\"Running concurrent requests...\")\n",
    "await multiple_requests()\n",
    "print(\"All requests completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Error Handling and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import APIError, RateLimitError\n",
    "import time\n",
    "\n",
    "def robust_chat(prompt, max_retries=3):\n",
    "    \"\"\"Chat with comprehensive error handling\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            message = client.messages.create(\n",
    "                model=\"claude-sonnet-4-20250514\",\n",
    "                max_tokens=1000,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"response\": message.content[0].text,\n",
    "                \"usage\": message.usage.dict() if hasattr(message, 'usage') else None\n",
    "            }\n",
    "            \n",
    "        except RateLimitError:\n",
    "            wait_time = (2 ** attempt) + 1  # Exponential backoff\n",
    "            print(f\"Rate limit hit. Waiting {wait_time}s...\")\n",
    "            time.sleep(wait_time)\n",
    "            \n",
    "        except APIError as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"API Error: {str(e)}\"\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Unexpected error: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    return {\n",
    "        \"success\": False,\n",
    "        \"error\": \"Max retries exceeded\"\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "result = robust_chat(\"Explain the importance of error handling in APIs\")\n",
    "print(f\"Success: {result['success']}\")\n",
    "if result['success']:\n",
    "    print(f\"Response: {result['response'][:200]}...\")\n",
    "    if result['usage']:\n",
    "        print(f\"Tokens used: {result['usage']}\")\n",
    "else:\n",
    "    print(f\"Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cost Optimization Tips\n",
    "\n",
    "**Model Selection**: Choose the right model for your task\n",
    "- Use Haiku for simple, fast responses\n",
    "- Use Sonnet for balanced performance\n",
    "- Use Opus only for complex reasoning tasks\n",
    "\n",
    "**Prompt Caching**: Cache frequently used prompts (90% savings)\n",
    "**Batch Processing**: Use batch API for 50% cost reduction on non-urgent tasks\n",
    "**Token Management**: Monitor input/output token usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cost(input_tokens, output_tokens, model=\"claude-sonnet-4-20250514\"):\n",
    "    \"\"\"Estimate API costs\"\"\"\n",
    "    pricing = {\n",
    "        \"claude-opus-4-20250514\": {\"input\": 15, \"output\": 75},\n",
    "        \"claude-sonnet-4-20250514\": {\"input\": 3, \"output\": 15},\n",
    "        \"claude-3-5-haiku-20241022\": {\"input\": 0.8, \"output\": 4}\n",
    "    }\n",
    "    \n",
    "    if model not in pricing:\n",
    "        return \"Unknown model\"\n",
    "    \n",
    "    costs = pricing[model]\n",
    "    input_cost = (input_tokens / 1_000_000) * costs[\"input\"]\n",
    "    output_cost = (output_tokens / 1_000_000) * costs[\"output\"]\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    return {\n",
    "        \"input_cost\": f\"${input_cost:.6f}\",\n",
    "        \"output_cost\": f\"${output_cost:.6f}\", \n",
    "        \"total_cost\": f\"${total_cost:.6f}\"\n",
    "    }\n",
    "\n",
    "# Example cost calculation\n",
    "cost = estimate_cost(1000, 500, \"claude-sonnet-4-20250514\")\n",
    "print(f\"Cost estimate: {cost}\")\n",
    "\n",
    "print(\"\\n=== Tutorial Complete! ===\")\n",
    "print(\"You now know the essentials of Claude API:\")\n",
    "print(\"â Authentication and setup\")\n",
    "print(\"â Text generation with Claude 4 models\")\n",
    "print(\"â Streaming for real-time responses\")\n",
    "print(\"â Vision capabilities for images\")\n",
    "print(\"â Tool use for enhanced functionality\")\n",
    "print(\"â Async operations for performance\")\n",
    "print(\"â Error handling and cost optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This tutorial covered the essential Claude API concepts. For advanced use cases, explore:\n",
    "\n",
    "**Advanced Features**:\n",
    "- Prompt caching for cost optimization\n",
    "- Extended thinking mode with Claude 4\n",
    "- Computer use capabilities\n",
    "- Custom tool integrations\n",
    "\n",
    "**Production Considerations**:\n",
    "- Rate limiting and retry logic\n",
    "- Monitoring and logging\n",
    "- Security best practices\n",
    "- Scalability patterns\n",
    "\n",
    "**Resources**:\n",
    "- [Official Documentation](https://docs.anthropic.com)\n",
    "- [API Reference](https://docs.anthropic.com/en/api)\n",
    "- [Anthropic Cookbook](https://github.com/anthropics/anthropic-cookbook)\n",
    "- [Community Discord](https://discord.gg/anthropic)\n",
    "\n",
    "Happy building with Claude! ð"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
