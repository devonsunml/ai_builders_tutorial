{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langfuse Tutorial: LLM Observability & Evaluation\n",
    "\n",
    "This is a getting-started tutorial on **Langfuse**, the open-source LLM engineering platform. This notebook covers all essential concepts you need to get started with LLM observability, evaluation, and prompt management.\n",
    "\n",
    "## What is Langfuse?\n",
    "\n",
    "Langfuse is an open-source platform that helps teams:\n",
    "- **Observe** LLM applications through detailed tracing\n",
    "- **Evaluate** model performance with various scoring methods  \n",
    "- **Manage** prompts collaboratively with version control\n",
    "- **Debug** and improve LLM applications in production\n",
    "\n",
    "## Key Features We'll Cover\n",
    "\n",
    "1. **Setup & Basic Tracing** - Get started with observability\n",
    "2. **LLM Integration** - Integrate with OpenAI and capture usage\n",
    "3. **Prompt Management** - Version and manage prompts centrally\n",
    "4. **Evaluation & Scoring** - Assess model quality with various methods\n",
    "5. **Datasets** - Create test sets for systematic evaluation\n",
    "6. **Analytics** - Monitor performance and gather insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install the required packages and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install langfuse openai python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Langfuse connection: True\n",
      "üìç Using Langfuse host: https://cloud.langfuse.com\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langfuse import Langfuse, observe\n",
    "from langfuse.openai import openai  # Langfuse OpenAI integration\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "LANGFUSE_PUBLIC_KEY = os.getenv(\"LANGFUSE_PUBLIC_KEY\")\n",
    "LANGFUSE_SECRET_KEY = os.getenv(\"LANGFUSE_SECRET_KEY\")\n",
    "LANGFUSE_HOST = os.getenv(\"LANGFUSE_HOST\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize Langfuse client\n",
    "langfuse = Langfuse()\n",
    "\n",
    "# Test connection\n",
    "print(\"‚úÖ Langfuse connection:\", langfuse.auth_check())\n",
    "print(\"üìç Using Langfuse host:\", LANGFUSE_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Tracing with Decorators\n",
    "\n",
    "The `@observe()` decorator is the simplest way to add observability to your functions. It automatically creates traces and spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response: Renewable energy offers numerous benefits, including reduced greenhouse gas emissions, decreased air pollution, and enhanced energy security. It promotes sustainable economic growth and job creation while decreasing dependence on fossil fuels. Additionally, renewable sources, such as solar and wind, are abundant and can provide long-term, reliable energy solutions.\n"
     ]
    }
   ],
   "source": [
    "@observe()\n",
    "def data_preprocessing(text: str):\n",
    "    \"\"\"Simulate data preprocessing step\"\"\"\n",
    "    cleaned_text = text.strip().lower()\n",
    "    return cleaned_text\n",
    "\n",
    "@observe(as_type=\"generation\")\n",
    "def generate_response(prompt: str):\n",
    "    \"\"\"Generate AI response using OpenAI\"\"\"\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "@observe()\n",
    "def ai_assistant(user_input: str):\n",
    "    \"\"\"Main AI assistant function\"\"\"\n",
    "    # Process input and generate response\n",
    "    processed_input = data_preprocessing(user_input)\n",
    "    response = generate_response(processed_input)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test the traced function\n",
    "result = ai_assistant(\"Explain what are the benefits of renewable energy in 50 words\")\n",
    "print(\"AI Response:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Langfuse Screenshot](/langfuse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prompt Management\n",
    "\n",
    "Langfuse allows you to manage prompts centrally with version control and collaborative editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: AI revolutionizes industries through machine learning and deep learning applications.\n"
     ]
    }
   ],
   "source": [
    "# Create a managed prompt\n",
    "langfuse.create_prompt(\n",
    "    name=\"content-summarizer\",\n",
    "    prompt=\"You are an expert content summarizer. Summarize the following text in {{max_words}} words, focusing on {{focus_area}}.\\n\\nText: {{content}}\",\n",
    "    config={\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 200\n",
    "    },\n",
    "    labels=[\"production\"]  # Mark as production version\n",
    ")\n",
    "\n",
    "@observe()\n",
    "def summarize_content(content: str, max_words: int = 50, focus_area: str = \"key insights\"):\n",
    "    \"\"\"Summarize content using managed prompt\"\"\"\n",
    "    # Get the current prompt version\n",
    "    prompt = langfuse.get_prompt(\"content-summarizer\")\n",
    "    \n",
    "    # Format prompt with variables\n",
    "    formatted_prompt = prompt.prompt.replace(\"{{content}}\", content)\n",
    "    formatted_prompt = formatted_prompt.replace(\"{{max_words}}\", str(max_words))\n",
    "    formatted_prompt = formatted_prompt.replace(\"{{focus_area}}\", focus_area)\n",
    "    \n",
    "    # Use prompt config for model parameters\n",
    "    response = openai.chat.completions.create(\n",
    "        model=prompt.config[\"model\"],\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "        temperature=prompt.config[\"temperature\"],\n",
    "        max_tokens=prompt.config[\"max_tokens\"]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test prompt management\n",
    "sample_text = \"Artificial intelligence is transforming industries worldwide. Machine learning algorithms enable computers to learn from data without explicit programming. Deep learning, a subset of ML, uses neural networks to solve complex problems. Applications include image recognition, natural language processing, and autonomous vehicles.\"\n",
    "\n",
    "summary = summarize_content(sample_text, max_words=10, focus_area=\"technological impact\")\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation and Scoring\n",
    "\n",
    "Langfuse supports various evaluation methods including custom scores, user feedback, and LLM-as-a-judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "summary: Climate change poses significant challenges, including rising temperatures, melting ice caps, and extreme weather. Renewable energy sources like solar and wind power provide sustainable alternatives to fossil fuels, with global investments in clean technology aimed at reducing carbon emissions and environmental impact.\n",
      "quality_score: 9.0\n",
      "word_count: 42\n",
      "trace_id: ff8e2ba59f681fcd6943f24d08a769e2\n"
     ]
    }
   ],
   "source": [
    "@observe()\n",
    "def evaluate_response_quality(original_text: str, summary: str):\n",
    "    \"\"\"Evaluate summary quality using LLM-as-a-judge\"\"\"\n",
    "    \n",
    "    # LLM-as-a-judge evaluation\n",
    "    eval_prompt = f\"\"\"\n",
    "    Evaluate the quality of this summary on a scale of 1-10:\n",
    "    \n",
    "    Original Text: {original_text}\n",
    "    Summary: {summary}\n",
    "    \n",
    "    Rate the summary based on:\n",
    "    - Accuracy (captures key information)\n",
    "    - Conciseness (appropriate length)\n",
    "    - Clarity (easy to understand)\n",
    "    \n",
    "    Respond with only a number from 1-10.\n",
    "    \"\"\"\n",
    "    \n",
    "    eval_response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": eval_prompt}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        quality_score = float(eval_response.choices[0].message.content.strip())\n",
    "    except ValueError:\n",
    "        quality_score = 5.0  # Default score if parsing fails\n",
    "    \n",
    "    return quality_score\n",
    "\n",
    "@observe()\n",
    "def comprehensive_ai_pipeline(user_input: str):\n",
    "    \"\"\"Complete AI pipeline with evaluation\"\"\"\n",
    "    # Generate summary\n",
    "    summary = summarize_content(user_input, max_words=40)\n",
    "    \n",
    "    # Evaluate quality\n",
    "    quality_score = evaluate_response_quality(user_input, summary)\n",
    "    \n",
    "    # Add custom scores to the trace using the correct Langfuse 3.2.1 API\n",
    "    langfuse.score_current_trace(\n",
    "        name=\"quality\",\n",
    "        value=quality_score,\n",
    "        comment=f\"LLM-as-a-judge quality evaluation\"\n",
    "    )\n",
    "    \n",
    "    # Add custom metrics\n",
    "    word_count_score = len(summary.split())\n",
    "    langfuse.score_current_trace(\n",
    "        name=\"word_count\",\n",
    "        value=word_count_score,\n",
    "        comment=\"Number of words in summary\"\n",
    "    )\n",
    "    \n",
    "    # Simulate user feedback (in practice, this would come from your app)\n",
    "    user_rating = 4  # Scale of 1-5\n",
    "    langfuse.score_current_trace(\n",
    "        name=\"user_satisfaction\",\n",
    "        value=user_rating,\n",
    "        comment=\"Simulated user feedback\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"quality_score\": quality_score,\n",
    "        \"word_count\": word_count_score,\n",
    "        \"trace_id\": langfuse.get_current_trace_id()\n",
    "    }\n",
    "\n",
    "# Test evaluation pipeline\n",
    "sample_article = \"Climate change is one of the most pressing challenges of our time. Rising global temperatures are causing ice caps to melt, sea levels to rise, and weather patterns to become more extreme. Renewable energy sources like solar and wind power offer sustainable alternatives to fossil fuels. Governments and businesses worldwide are investing in clean technology to reduce carbon emissions and mitigate environmental impact.\"\n",
    "\n",
    "result = comprehensive_ai_pipeline(sample_article)\n",
    "print(\"Results:\")\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Datasets for Testing\n",
    "\n",
    "Create datasets to systematically test your LLM applications and track performance over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Evaluation Results:\n",
      "\n",
      "Test Case 1:\n",
      "Input: Machine learning is a subset of artificial intelli...\n",
      "Generated: Machine learning, a subset of artificial intelligence, allows computers to learn from data and make decisions using algorithms that identify patterns and predictions.\n",
      "Similarity: 0.31\n",
      "\n",
      "Test Case 2:\n",
      "Input: The human brain contains approximately 86 billion ...\n",
      "Generated: The human brain has about 86 billion neurons that communicate via signals, facilitating cognitive functions such as memory, learning, and decision-making.\n",
      "Similarity: 0.444\n",
      "\n",
      "Test Case 3:\n",
      "Input: Renewable energy sources such as solar, wind, and ...\n",
      "Generated: Renewable energy sources like solar, wind, and hydroelectric power are vital alternatives to fossil fuels, providing sustainable solutions to rising energy demands and minimizing environmental impact.\n",
      "Similarity: 0.538\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset for testing\n",
    "dataset_name = \"text-summarization-test\"\n",
    "\n",
    "# Create dataset\n",
    "langfuse.create_dataset(\n",
    "    name=dataset_name,\n",
    "    description=\"Test cases for text summarization quality\",\n",
    "    metadata={\"version\": \"1.0\", \"purpose\": \"quality_testing\"}\n",
    ")\n",
    "\n",
    "# Add test cases to dataset\n",
    "test_cases = [\n",
    "    {\n",
    "        \"input\": \"Machine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed. It involves algorithms that can identify patterns and make predictions.\",\n",
    "        \"expected_output\": \"Machine learning uses algorithms to help computers learn from data and make predictions without explicit programming.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"The human brain contains approximately 86 billion neurons that communicate through electrical and chemical signals. These neural networks process information and enable cognitive functions like memory, learning, and decision-making.\",\n",
    "        \"expected_output\": \"The brain has 86 billion neurons that communicate via signals to enable cognitive functions like memory and learning.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Renewable energy sources such as solar, wind, and hydroelectric power are becoming increasingly important as alternatives to fossil fuels. They offer sustainable solutions to meet growing energy demands while reducing environmental impact.\",\n",
    "        \"expected_output\": \"Solar, wind, and hydroelectric power are sustainable renewable energy alternatives to fossil fuels with less environmental impact.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Add items to dataset\n",
    "for i, case in enumerate(test_cases):\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=dataset_name,\n",
    "        input=case[\"input\"],\n",
    "        expected_output=case[\"expected_output\"],\n",
    "        metadata={\"test_case_id\": i+1}\n",
    "    )\n",
    "\n",
    "@observe()\n",
    "def run_dataset_evaluation():\n",
    "    \"\"\"Run evaluation on dataset items\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for case in test_cases:\n",
    "        # Generate summary\n",
    "        generated_summary = summarize_content(case[\"input\"], max_words=25)\n",
    "        \n",
    "        # Compare with expected output (simple similarity check)\n",
    "        expected_words = set(case[\"expected_output\"].lower().split())\n",
    "        generated_words = set(generated_summary.lower().split())\n",
    "        \n",
    "        # Calculate word overlap similarity\n",
    "        intersection = expected_words.intersection(generated_words)\n",
    "        union = expected_words.union(generated_words)\n",
    "        similarity = len(intersection) / len(union) if union else 0\n",
    "        \n",
    "        # Score the result using the correct Langfuse 3.2.1 API\n",
    "        langfuse.score_current_trace(\n",
    "            name=\"similarity_score\",\n",
    "            value=similarity,\n",
    "            comment=f\"Word overlap similarity with expected output\"\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            \"input\": case[\"input\"][:50] + \"...\",\n",
    "            \"generated\": generated_summary,\n",
    "            \"expected\": case[\"expected_output\"],\n",
    "            \"similarity\": round(similarity, 3)\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run dataset evaluation\n",
    "eval_results = run_dataset_evaluation()\n",
    "print(\"Dataset Evaluation Results:\")\n",
    "for i, result in enumerate(eval_results, 1):\n",
    "    print(f\"\\nTest Case {i}:\")\n",
    "    print(f\"Input: {result['input']}\")\n",
    "    print(f\"Generated: {result['generated']}\")\n",
    "    print(f\"Similarity: {result['similarity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "üéâ **Congratulations!** You've completed the comprehensive Langfuse tutorial. Here's what you've learned:\n",
    "\n",
    "### Key Concepts Covered:\n",
    "\n",
    "1. **Setup & Basic Tracing** - Using `@observe()` decorators for automatic observability\n",
    "2. **LLM Integration** - Seamless OpenAI integration with usage tracking\n",
    "3. **Prompt Management** - Centralized prompt versioning and configuration\n",
    "4. **Evaluation & Scoring** - Multiple evaluation methods including LLM-as-a-judge\n",
    "5. **Datasets** - Creating test sets for systematic quality assessment\n",
    "6. **Analytics** - Performance monitoring and insights\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- **Visit your Langfuse dashboard** to see your traces\n",
    "- **Explore advanced features** like custom evaluators and production monitoring\n",
    "- **Integrate with your existing LLM applications** using the patterns learned here\n",
    "\n",
    "Happy building! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
