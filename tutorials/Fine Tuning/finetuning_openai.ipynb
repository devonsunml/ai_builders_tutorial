{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Model Fine-Tuning Tutorial\n",
    "\n",
    "Welcome to this tutorial on fine-tuning OpenAI models! ðŸš€\n",
    "\n",
    "Fine-tuning is a powerful technique to adapt a pre-trained model to your specific task. By training the model on a smaller, task-specific dataset, you can significantly improve its performance, making it more accurate and relevant to your needs. This process can also lead to cost savings and faster response times as your prompts can be shorter and more direct.\n",
    "\n",
    "This notebook will walk you through the essential concepts and practical steps of fine-tuning, including:\n",
    "\n",
    "* **Data Preparation**: Creating high-quality training and validation datasets in the required JSONL format.\n",
    "* **Supervised Fine-Tuning (SFT)**: The most common fine-tuning method, where the model learns from labeled examples.\n",
    "* **Using a Fine-Tuned Model**: Making API calls to your newly customized model.\n",
    "\n",
    "We'll also briefly touch on more advanced techniques like **Direct Preference Optimization (DPO)** and fine-tuning for **Function Calling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install the necessary libraries and load our API keys from a `.env` file. This is a best practice for keeping your keys secure. Create a file named `.env` in the same directory as this notebook and add your OpenAI API key to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install the required packages\n",
    "# %pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "The quality of your fine-tuned model heavily depends on the quality of your training data. For supervised fine-tuning, the data needs to be in a **JSONL** (JSON Lines) format, where each line is a separate JSON object representing a single training example.\n",
    "\n",
    "Each JSON object should contain a `messages` array, following the chat completions format. This array consists of a series of messages, each with a `role` (`system`, `user`, or `assistant`) and `content`.\n",
    "\n",
    "Let's create a simple training and validation dataset for a chatbot that responds in the style of a pirate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "training_data = [\n",
    "    # Add at least 10 training examples here\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"Hello, who are you?\"}, {\"role\": \"assistant\", \"content\": \"Ahoy! I be a pirate assistant, ready to help ye with yer queries.\"}]},\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"What's the weather like?\"}, {\"role\": \"assistant\", \"content\": \"The sky be clear and the winds be fair, a perfect day for sailin' the seven seas!\"}]},\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"Tell me a joke.\"}, {\"role\": \"assistant\", \"content\": \"Why don't pirates take a shower before they walk the plank? Because they'll just wash up on shore later!\"}]},\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"How do pirates say hello?\"}, {\"role\": \"assistant\", \"content\": \"They say 'Ahoy, matey!' with a big grin!\"}]},\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"What's your favorite food?\"}, {\"role\": \"assistant\", \"content\": \"Arrr, I love hardtack and salted pork, the staples of the sea!\"}]},\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"Do you have a pet?\"}, {\"role\": \"assistant\", \"content\": \"Aye, I have a trusty parrot who sits on me shoulder!\"}]},\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"What's your ship called?\"}, {\"role\": \"assistant\", \"content\": \"She be called The Black Pearl, the fastest ship on the seas!\"}]},\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"How do pirates celebrate?\"}, {\"role\": \"assistant\", \"content\": \"With a hearty 'Yo-ho-ho!' and a barrel of rum!\"}]},\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"What's your favorite treasure?\"}, {\"role\": \"assistant\", \"content\": \"Gold doubloons and sparkling jewels, of course!\"}]},\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"Can you sing a pirate song?\"}, {\"role\": \"assistant\", \"content\": \"Yo-ho-ho, a pirate's life for me!\"}]}\n",
    "]\n",
    "\n",
    "validation_data = [\n",
    "    {\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"}, {\"role\": \"user\", \"content\": \"What's for dinner?\"}, {\"role\": \"assistant\", \"content\": \"We be havin' a grand feast of salted pork and hardtack, the finest grub on the high seas!\"}]},\n",
    "]\n",
    "\n",
    "# Check that there are at least 10 training examples\n",
    "if len(training_data) < 10:\n",
    "    raise ValueError(f\"You must provide at least 10 training examples for fine-tuning. Currently: {len(training_data)}\")\n",
    "\n",
    "# Save to JSONL files\n",
    "with open(\"training_set.jsonl\", \"w\") as f:\n",
    "    for item in training_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "with open(\"validation_set.jsonl\", \"w\") as f:\n",
    "    for item in validation_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Supervised Fine-Tuning (SFT)\n",
    "\n",
    "Now that we have our data, we can start the fine-tuning process. This involves three main steps:\n",
    "\n",
    "1.  **Upload the training and validation files** to OpenAI.\n",
    "2.  **Create a fine-tuning job** with the uploaded files and a base model.\n",
    "3.  **Monitor the job** until it's complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-VzC1XgH4PiieQQDo2Tg3Lm\n",
      "Validation file ID: file-Xsx4gwPXvFv3jxGTxn8rmn\n"
     ]
    }
   ],
   "source": [
    "# Upload the training and validation files\n",
    "training_file = client.files.create(\n",
    "  file=open(\"training_set.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "validation_file = client.files.create(\n",
    "  file=open(\"validation_set.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(f\"Training file ID: {training_file.id}\")\n",
    "print(f\"Validation file ID: {validation_file.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job ID: ftjob-CiGXJ8BE4xCwiej9Nbb3iFKa\n"
     ]
    }
   ],
   "source": [
    "# Create a fine-tuning job\n",
    "fine_tuning_job = client.fine_tuning.jobs.create(\n",
    "  training_file=training_file.id,\n",
    "  validation_file=validation_file.id,\n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning job ID: {fine_tuning_job.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: succeeded\n"
     ]
    }
   ],
   "source": [
    "# Monitor the fine-tuning job\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    job_status = client.fine_tuning.jobs.retrieve(fine_tuning_job.id).status\n",
    "    print(f\"Job status: {job_status}\")\n",
    "    if job_status in [\"succeeded\", \"failed\"]:\n",
    "        break\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using the Fine-Tuned Model\n",
    "\n",
    "Once the fine-tuning job is successful, you can retrieve the ID of your new model and use it in your API calls. The model ID will start with `ft:`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model ID: ft:gpt-3.5-turbo-0125:datumverse::C1BwJ05C\n",
      "The capital of France be Paris, aye!\n"
     ]
    }
   ],
   "source": [
    "# Get the fine-tuned model ID\n",
    "fine_tuned_model_id = client.fine_tuning.jobs.retrieve(fine_tuning_job.id).fine_tuned_model\n",
    "print(f\"Fine-tuned model ID: {fine_tuned_model_id}\")\n",
    "\n",
    "# Use the fine-tuned model\n",
    "if fine_tuned_model_id:\n",
    "    completion = client.chat.completions.create(\n",
    "      model=fine_tuned_model_id,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant who talks like a pirate.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "      ]\n",
    "    )\n",
    "    print(completion.choices[0].message.content)\n",
    "else:\n",
    "    print(\"Fine-tuning job not yet succeeded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Fine-Tuning\n",
    "\n",
    "Beyond Supervised Fine-Tuning, OpenAI offers more advanced methods:\n",
    "\n",
    "* **Direct Preference Optimization (DPO)**: This technique is useful when you want to align the model with human preferences. Instead of providing a single correct output, you provide pairs of preferred and rejected responses.\n",
    "\n",
    "* **Fine-tuning for Function Calling**: If you need your model to reliably output structured JSON for function calls, you can fine-tune it with examples of function call requests and responses.\n",
    "\n",
    "These methods follow a similar process of data preparation, upload, and job creation, but with different data formats. For more details, refer to the OpenAI documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've learned the fundamentals of fine-tuning OpenAI models. By creating high-quality datasets and following the steps in this tutorial, you can create powerful, customized models for your specific applications.\n",
    "\n",
    "Remember that fine-tuning is an iterative process. Start with a small, high-quality dataset, evaluate your model's performance, and gradually expand and refine your data to achieve the best results. Happy fine-tuning! ðŸ¦œ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
