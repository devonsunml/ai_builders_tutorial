{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nosana AI Inference Tutorial with Python\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Nosana is a GPU marketplace that makes AI compute accessible and affordable. This tutorial demonstrates how to interact with deployed AI models on the Nosana network, including multimodal understanding and text-to-image generation.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Connect to deployed Nosana AI services via API\n",
    "- Perform multimodal image understanding tasks\n",
    "- Generate images from text prompts\n",
    "- Deploy your own AI services on Nosana\n",
    "- Cost optimization for GPU-powered AI inference\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- Basic understanding of AI/ML concepts\n",
    "- For deployment: Node.js, SOL tokens (0.05 SOL minimum), NOS tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install required packages\n",
    "# !pip install gradio_client requests pillow matplotlib python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from gradio_client import Client\n",
    "from typing import Dict, List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to Deployed Nosana AI Services\n",
    "\n",
    "This example uses a live multimodal AI service deployed on Nosana that provides:\n",
    "- **Multimodal Understanding**: Analyze images and answer questions\n",
    "- **Text-to-Image Generation**: Create images from text descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NosanaAIClient:\n",
    "    \"\"\"Python client for interacting with Nosana-deployed AI services\"\"\"\n",
    "    \n",
    "    def __init__(self, service_url: str):\n",
    "        self.service_url = service_url.rstrip('/')\n",
    "        self.client = Client(service_url)\n",
    "        print(f\"üöÄ Connected to Nosana AI service: {service_url}\")\n",
    "    \n",
    "    def understand_image(self, \n",
    "                        image_path: str, \n",
    "                        question: str,\n",
    "                        seed: int = 42,\n",
    "                        top_p: float = 0.95,\n",
    "                        temperature: float = 0.1) -> str:\n",
    "        \"\"\"Analyze image and answer questions using multimodal AI\"\"\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"üîç Analyzing image: {image_path}\")\n",
    "            print(f\"‚ùì Question: {question}\")\n",
    "            \n",
    "            result = self.client.predict(\n",
    "                image_path,\n",
    "                question,\n",
    "                seed,\n",
    "                top_p,\n",
    "                temperature,\n",
    "                fn_index=2\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Analysis complete!\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"‚ùå Image analysis failed: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return error_msg\n",
    "    \n",
    "    def generate_image(self,\n",
    "                      prompt: str,\n",
    "                      seed: int = 12345,\n",
    "                      cfg_weight: float = 5.0,\n",
    "                      temperature: float = 1.0) -> str:\n",
    "        \"\"\"Generate images from text prompts\"\"\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"üé® Generating image from prompt: {prompt[:50]}...\")\n",
    "            \n",
    "            result = self.client.predict(\n",
    "                prompt,\n",
    "                seed,\n",
    "                cfg_weight,\n",
    "                temperature,\n",
    "                fn_index=3\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Image generation complete!\")\n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"‚ùå Image generation failed: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return error_msg\n",
    "    \n",
    "    def test_connection(self) -> bool:\n",
    "        \"\"\"Test if the service is accessible\"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.service_url, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                print(f\"‚úÖ Service is online and accessible\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Service returned status: {response.status_code}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Connection test failed: {e}\")\n",
    "            return False\n",
    "\n",
    "# Initialize client with deployed Nosana service\n",
    "NOSANA_SERVICE_URL = \"https://53mnfyl8sretv69hx9dhhnaqaxj8qrzwg6qpfd62tbtq.node.k8s.prd.nos.ci/\"\n",
    "ai_client = NosanaAIClient(NOSANA_SERVICE_URL)\n",
    "\n",
    "# Test connection\n",
    "ai_client.test_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Image Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Analyze a meme (as shown in the document)\n",
    "meme_url = \"https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png\"\n",
    "\n",
    "# Download and display the image\n",
    "response = requests.get(meme_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Image for Analysis')\n",
    "plt.show()\n",
    "\n",
    "# Analyze the image\n",
    "analysis = ai_client.understand_image(\n",
    "    image_path=meme_url,\n",
    "    question=\"What do you see in this image? Describe it in detail.\",\n",
    "    seed=42,\n",
    "    top_p=0.95,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "print(\"\\nüìù AI Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(analysis)\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Multiple questions about the same image\n",
    "questions = [\n",
    "    \"What objects can you identify in this image?\",\n",
    "    \"What colors are prominent in this image?\",\n",
    "    \"Is this image taken indoors or outdoors?\",\n",
    "    \"What might be the context or setting of this image?\"\n",
    "]\n",
    "\n",
    "print(\"üß† Multi-Question Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\n{i}. {question}\")\n",
    "    answer = ai_client.understand_image(\n",
    "        image_path=meme_url,\n",
    "        question=question,\n",
    "        temperature=0.2  # Lower temperature for more consistent answers\n",
    "    )\n",
    "    print(f\"üí° Answer: {answer}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prompts for image generation\n",
    "creative_prompts = [\n",
    "    \"A cute and adorable baby fox with big brown eyes, autumn leaves in the background\",\n",
    "    \"Astronaut in a jungle, cold color palette, muted colors, detailed, 8k\",\n",
    "    \"A glass of red wine on a reflective surface, cinematic lighting\",\n",
    "    \"Master shifu raccoon wearing drip attire as a street gangster\"\n",
    "]\n",
    "\n",
    "def generate_and_display_images(prompts: List[str], max_images: int = 2):\n",
    "    \"\"\"Generate multiple images and display results\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, prompt in enumerate(prompts[:max_images]):\n",
    "        print(f\"\\nüé® Generating image {i+1}/{min(len(prompts), max_images)}...\")\n",
    "        \n",
    "        # Generate image with different seeds for variety\n",
    "        result = ai_client.generate_image(\n",
    "            prompt=prompt,\n",
    "            seed=12345 + i * 100,  # Different seed for each image\n",
    "            cfg_weight=5.0,\n",
    "            temperature=1.0\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'prompt': prompt,\n",
    "            'result': result\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Image {i+1} generated successfully!\")\n",
    "        print(f\"üìÅ Result path: {result}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generate images\n",
    "print(\"üöÄ Starting image generation with Nosana AI...\")\n",
    "generated_images = generate_and_display_images(creative_prompts, max_images=2)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nüìä Generation Summary:\")\n",
    "for i, img_data in enumerate(generated_images, 1):\n",
    "    print(f\"{i}. Prompt: {img_data['prompt'][:50]}...\")\n",
    "    print(f\"   Result: {img_data['result']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced AI Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NosanaAIWorkflow:\n",
    "    \"\"\"Advanced workflows combining multiple AI capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, ai_client: NosanaAIClient):\n",
    "        self.client = ai_client\n",
    "    \n",
    "    def analyze_and_enhance_prompt(self, image_url: str) -> str:\n",
    "        \"\"\"Analyze an image and create an enhanced prompt for generation\"\"\"\n",
    "        \n",
    "        # First, analyze the image\n",
    "        analysis = self.client.understand_image(\n",
    "            image_path=image_url,\n",
    "            question=\"Describe this image in detail, focusing on style, colors, composition, and artistic elements that could be used to generate a similar image.\",\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        # Create enhanced prompt based on analysis\n",
    "        enhanced_prompt = f\"High quality artistic image inspired by: {analysis}, detailed, professional photography, 8k resolution\"\n",
    "        \n",
    "        return enhanced_prompt\n",
    "    \n",
    "    def batch_image_analysis(self, image_urls: List[str], base_question: str) -> Dict:\n",
    "        \"\"\"Analyze multiple images with the same question\"\"\"\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for i, url in enumerate(image_urls):\n",
    "            print(f\"üì∏ Analyzing image {i+1}/{len(image_urls)}...\")\n",
    "            \n",
    "            analysis = self.client.understand_image(\n",
    "                image_path=url,\n",
    "                question=base_question,\n",
    "                seed=42 + i,\n",
    "                temperature=0.2\n",
    "            )\n",
    "            \n",
    "            results[f\"image_{i+1}\"] = {\n",
    "                \"url\": url,\n",
    "                \"analysis\": analysis\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def progressive_image_generation(self, base_prompt: str, variations: int = 3) -> List[str]:\n",
    "        \"\"\"Generate variations of an image with progressive modifications\"\"\"\n",
    "        \n",
    "        style_modifiers = [\n",
    "            \"photorealistic, highly detailed\",\n",
    "            \"artistic, painterly style, vibrant colors\", \n",
    "            \"minimalist, clean composition, soft lighting\"\n",
    "        ]\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i in range(min(variations, len(style_modifiers))):\n",
    "            modified_prompt = f\"{base_prompt}, {style_modifiers[i]}\"\n",
    "            \n",
    "            print(f\"üé® Generating variation {i+1}: {style_modifiers[i]}\")\n",
    "            \n",
    "            result = self.client.generate_image(\n",
    "                prompt=modified_prompt,\n",
    "                seed=12345 + i * 50,\n",
    "                cfg_weight=5.0 + i * 0.5,  # Slightly different CFG for each\n",
    "                temperature=1.0\n",
    "            )\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize workflow manager\n",
    "workflow = NosanaAIWorkflow(ai_client)\n",
    "\n",
    "# Example: Progressive image generation\n",
    "base_prompt = \"A serene mountain landscape at sunset\"\n",
    "print(f\"üåÑ Creating variations of: {base_prompt}\")\n",
    "\n",
    "variations = workflow.progressive_image_generation(base_prompt, variations=2)\n",
    "\n",
    "print(\"\\n‚úÖ Generated variations:\")\n",
    "for i, result in enumerate(variations, 1):\n",
    "    print(f\"{i}. {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Your Own AI Services on Nosana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NosanaDeploymentManager:\n",
    "    \"\"\"Manage Nosana AI service deployments\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.markets = {\n",
    "            \"nvidia-3060\": \"7AtiXMSH6R1jjBxrcYjehCkkSF7zvYWte63gwEDBcGHq\",\n",
    "            \"nvidia-3090\": \"97G9NnvBDQ2WpKu6fasoMsAKmfj63C9rhysJnkeWodAf\"\n",
    "        }\n",
    "    \n",
    "    def create_gradio_ai_job(self, \n",
    "                            model_name: str = \"multimodal-ai\",\n",
    "                            port: int = 7860) -> Dict:\n",
    "        \"\"\"Create job definition for Gradio-based AI service\"\"\"\n",
    "        \n",
    "        job_definition = {\n",
    "            \"version\": \"0.1\",\n",
    "            \"type\": \"container\",\n",
    "            \"meta\": {\"trigger\": \"python-ai-deploy\"},\n",
    "            \"ops\": [{\n",
    "                \"type\": \"container/run\",\n",
    "                \"id\": f\"{model_name}-service\",\n",
    "                \"args\": {\n",
    "                    \"cmd\": [\n",
    "                        \"python\", \"-c\",\n",
    "                        \"import gradio as gr; \"\n",
    "                        \"import torch; \"\n",
    "                        \"print('GPU Available:', torch.cuda.is_available()); \"\n",
    "                        \"gr.Interface(lambda x: f'Hello from Nosana GPU! Input: {x}', 'text', 'text').launch(server_name='0.0.0.0', server_port=7860)\"\n",
    "                    ],\n",
    "                    \"expose\": port,\n",
    "                    \"image\": \"pytorch/pytorch:2.0.1-cuda11.7-cudnn8-devel\",\n",
    "                    \"gpu\": True,\n",
    "                    \"env\": {\n",
    "                        \"CUDA_VISIBLE_DEVICES\": \"0\",\n",
    "                        \"GRADIO_SERVER_NAME\": \"0.0.0.0\"\n",
    "                    }\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        return job_definition\n",
    "    \n",
    "    def save_job_definition(self, job_def: Dict, filename: str = \"ai_service.json\") -> str:\n",
    "        \"\"\"Save job definition to file\"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(job_def, f, indent=2)\n",
    "        return filename\n",
    "    \n",
    "    def deploy_ai_service(self, \n",
    "                         job_file: str,\n",
    "                         market: str = \"nvidia-3060\",\n",
    "                         timeout: int = 120) -> Dict:\n",
    "        \"\"\"Deploy AI service to Nosana network\"\"\"\n",
    "        \n",
    "        import subprocess\n",
    "        \n",
    "        cmd = [\n",
    "            \"nosana\", \"job\", \"post\",\n",
    "            \"--file\", job_file,\n",
    "            \"--market\", market,\n",
    "            \"--timeout\", str(timeout)\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "            return {\"success\": True, \"output\": result.stdout}\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            return {\"success\": False, \"error\": e.stderr}\n",
    "\n",
    "# Example: Create and save deployment definition\n",
    "deployment_manager = NosanaDeploymentManager()\n",
    "\n",
    "# Create AI service job definition\n",
    "ai_job = deployment_manager.create_gradio_ai_job(\"custom-ai-service\")\n",
    "job_file = deployment_manager.save_job_definition(ai_job, \"custom_ai_service.json\")\n",
    "\n",
    "print(f\"‚úÖ AI service job definition created: {job_file}\")\n",
    "print(\"\\nüìã Job Definition Preview:\")\n",
    "print(json.dumps(ai_job, indent=2))\n",
    "\n",
    "print(\"\\nüí° To deploy this service, ensure you have:\")\n",
    "print(\"   ‚Ä¢ Nosana CLI installed and configured\")\n",
    "print(\"   ‚Ä¢ Sufficient SOL (0.05 minimum) and NOS tokens\")\n",
    "print(f\"   ‚Ä¢ Run: nosana job post --file {job_file} --market nvidia-3060 --timeout 120\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Analysis for AI Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NosanaCostAnalyzer:\n",
    "    \"\"\"Analyze costs for AI inference on Nosana\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.market_rates = {\n",
    "            \"nvidia-3060\": 0.000043,  # NOS per second\n",
    "            \"nvidia-3090\": 0.000115   # NOS per second  \n",
    "        }\n",
    "        \n",
    "        # Estimated processing times for different AI tasks\n",
    "        self.task_times = {\n",
    "            \"image_analysis\": 10,      # seconds per image\n",
    "            \"image_generation\": 30,    # seconds per image\n",
    "            \"batch_processing\": 5,     # seconds per item in batch\n",
    "            \"model_loading\": 60        # initial model loading time\n",
    "        }\n",
    "    \n",
    "    def calculate_inference_cost(self, \n",
    "                               market: str,\n",
    "                               task_type: str, \n",
    "                               num_requests: int,\n",
    "                               include_startup: bool = True) -> Dict:\n",
    "        \"\"\"Calculate cost for AI inference tasks\"\"\"\n",
    "        \n",
    "        if market not in self.market_rates:\n",
    "            return {\"error\": f\"Unknown market: {market}\"}\n",
    "        \n",
    "        if task_type not in self.task_times:\n",
    "            return {\"error\": f\"Unknown task type: {task_type}\"}\n",
    "        \n",
    "        rate_per_second = self.market_rates[market]\n",
    "        task_time = self.task_times[task_type]\n",
    "        \n",
    "        # Calculate total time\n",
    "        processing_time = task_time * num_requests\n",
    "        startup_time = self.task_times[\"model_loading\"] if include_startup else 0\n",
    "        total_time = processing_time + startup_time\n",
    "        \n",
    "        # Calculate costs\n",
    "        total_cost = rate_per_second * total_time\n",
    "        cost_per_request = total_cost / num_requests if num_requests > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"market\": market,\n",
    "            \"task_type\": task_type,\n",
    "            \"num_requests\": num_requests,\n",
    "            \"processing_time_seconds\": processing_time,\n",
    "            \"startup_time_seconds\": startup_time,\n",
    "            \"total_time_seconds\": total_time,\n",
    "            \"total_cost_nos\": total_cost,\n",
    "            \"cost_per_request_nos\": cost_per_request,\n",
    "            \"hourly_rate_nos\": rate_per_second * 3600\n",
    "        }\n",
    "    \n",
    "    def compare_markets_for_workload(self, \n",
    "                                   task_type: str, \n",
    "                                   num_requests: int):\n",
    "        \"\"\"Compare costs across markets for specific workload\"\"\"\n",
    "        \n",
    "        print(f\"üí∞ Cost Comparison: {num_requests} {task_type} requests\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for market in self.market_rates:\n",
    "            cost_info = self.calculate_inference_cost(market, task_type, num_requests)\n",
    "            \n",
    "            print(f\"\\nüè™ {market}:\")\n",
    "            print(f\"   Total Cost: {cost_info['total_cost_nos']:.6f} NOS\")\n",
    "            print(f\"   Per Request: {cost_info['cost_per_request_nos']:.6f} NOS\") \n",
    "            print(f\"   Total Time: {cost_info['total_time_seconds']} seconds\")\n",
    "            print(f\"   Hourly Rate: {cost_info['hourly_rate_nos']:.4f} NOS/hour\")\n",
    "    \n",
    "    def recommend_market(self, \n",
    "                        task_type: str, \n",
    "                        num_requests: int, \n",
    "                        budget_nos: float) -> str:\n",
    "        \"\"\"Recommend best market based on budget and workload\"\"\"\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        for market in self.market_rates:\n",
    "            cost_info = self.calculate_inference_cost(market, task_type, num_requests)\n",
    "            \n",
    "            if cost_info['total_cost_nos'] <= budget_nos:\n",
    "                recommendations.append({\n",
    "                    'market': market,\n",
    "                    'cost': cost_info['total_cost_nos'],\n",
    "                    'efficiency': num_requests / cost_info['total_cost_nos']\n",
    "                })\n",
    "        \n",
    "        if not recommendations:\n",
    "            return \"Budget too low for any market\"\n",
    "        \n",
    "        # Sort by efficiency (requests per NOS)\n",
    "        best = max(recommendations, key=lambda x: x['efficiency'])\n",
    "        return best['market']\n",
    "\n",
    "# Cost analysis examples\n",
    "cost_analyzer = NosanaCostAnalyzer()\n",
    "\n",
    "# Compare costs for different AI tasks\n",
    "tasks = [\n",
    "    (\"image_analysis\", 100),\n",
    "    (\"image_generation\", 50),\n",
    "    (\"batch_processing\", 500)\n",
    "]\n",
    "\n",
    "for task_type, num_requests in tasks:\n",
    "    cost_analyzer.compare_markets_for_workload(task_type, num_requests)\n",
    "    \n",
    "    # Get recommendation for modest budget\n",
    "    recommended = cost_analyzer.recommend_market(task_type, num_requests, budget_nos=1.0)\n",
    "    print(f\"\\nüéØ Recommended market for {task_type}: {recommended}\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices & Next Steps\n",
    "\n",
    "### AI Inference Optimization\n",
    "- **Batch requests** when possible to reduce startup costs\n",
    "- **Choose appropriate GPU markets** based on model complexity\n",
    "- **Monitor processing times** to optimize timeout settings\n",
    "- **Cache results** for repeated queries\n",
    "\n",
    "### Cost Management\n",
    "- Start with nvidia-3060 for testing and development\n",
    "- Use nvidia-3090 for production and complex models\n",
    "- Factor in model loading time for cost calculations\n",
    "- Set reasonable timeouts to avoid unnecessary charges\n",
    "\n",
    "### Security & Reliability\n",
    "- Never hardcode API keys or private keys\n",
    "- Implement proper error handling and retries\n",
    "- Monitor service availability and performance\n",
    "- Use environment variables for sensitive configuration\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've learned how to:\n",
    "‚úÖ Connect to deployed Nosana AI services via Python\n",
    "‚úÖ Perform multimodal image understanding and text-to-image generation\n",
    "‚úÖ Build advanced AI workflows with multiple capabilities\n",
    "‚úÖ Deploy your own AI services on Nosana's GPU network\n",
    "‚úÖ Analyze and optimize costs for AI inference workloads\n",
    "\n",
    "**Next Steps:**\n",
    "1. Experiment with the live Nosana AI service using your own images and prompts\n",
    "2. Deploy your own AI models using the deployment templates\n",
    "3. Build production workflows combining multiple AI capabilities\n",
    "4. Join the [Nosana Discord](https://discord.gg/nosana) community\n",
    "5. Explore [dashboard.nosana.com](https://dashboard.nosana.com) for advanced management\n",
    "\n",
    "The Nosana network makes powerful GPU-accelerated AI accessible to everyone at fraction of traditional cloud costs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
